{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\judyw\\Desktop\\ESE527\\project\\.conda\\Lib\\site-packages\\medcat\\cat.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# conda activate ESE527\n",
    "# Import the library\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "from medcat.vocab import Vocab\n",
    "from medcat.cdb import CDB\n",
    "from medcat.cat import CAT\n",
    "from medcat.meta_cat import MetaCAT\n",
    "import textwrap\n",
    "from rich import print \n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepared data and model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Fixing config.linking.weighted_average_function since the value saved does not work properly. This is usually due to having loaded a model that was originally saved in older versions of python and thus something has gone wrong when loading the method. This fix should not affect usage, but if you wish to avoid the warning you may want to save the model pack again using a newer version of python (3.11 or later).\n",
      "c:\\Users\\judyw\\Desktop\\ESE527\\project\\.conda\\Lib\\site-packages\\pydantic\\main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `set[str]` but got `dict` with value `{}` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "WARNING:medcat.cdb:You have MedCAT version '1.15.0' installed while the CDB was exported by MedCAT version '1.2.dev361',\n",
      "which may or may not work. If you experience any compatibility issues, please reinstall MedCAT\n",
      "or download the compatible model.\n"
     ]
    }
   ],
   "source": [
    "# Load the vocab model we downloaded \n",
    "vocab = Vocab.load(\"medcat_models/vocab.dat\")\n",
    "# Load the cdb model you downloaded\n",
    "cdb = CDB.load('medcat_models/cdb.dat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\judyw\\Desktop\\ESE527\\project\\.conda\\Lib\\site-packages\\medcat\\meta_cat.py:430: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_cat.model.load_state_dict(torch.load(model_save_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# Run the medcat_status model\n",
    "mc_status = MetaCAT.load(\"medcat_models/meta_Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:medcat.pipe:Could not load spacy model from 'spacy_model'. Falling back to installed en_core_web_md. For best compatibility, we'd recommend packaging and using your model pack with the spacy model it was designed for\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judyw\\Desktop\\ESE527\\project\\.conda\\Lib\\site-packages\\medcat\\pipe.py\", line 52, in __init__\n",
      "    self._nlp = self._init_nlp(config)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judyw\\Desktop\\ESE527\\project\\.conda\\Lib\\site-packages\\medcat\\pipe.py\", line 76, in _init_nlp\n",
      "    return spacy.load(config.general.spacy_model, disable=config.general.spacy_disabled_components)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judyw\\Desktop\\ESE527\\project\\.conda\\Lib\\site-packages\\spacy\\__init__.py\", line 51, in load\n",
      "    return util.load_model(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judyw\\Desktop\\ESE527\\project\\.conda\\Lib\\site-packages\\spacy\\util.py\", line 472, in load_model\n",
      "    raise IOError(Errors.E050.format(name=name))\n",
      "OSError: [E050] Can't find model 'spacy_model'. It doesn't seem to be a Python package or a valid path to a data directory.\n"
     ]
    }
   ],
   "source": [
    "# Initial the CAT\n",
    "# Please run twice\n",
    "cat = CAT(cdb=cdb, config=cdb.config, vocab=vocab, meta_cats=[mc_status])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the MIMIC-III data\n",
    "# Read all of csv file\n",
    "# Read the required csv file first\n",
    "note_event_df = pd.read_csv('Data/NOTEEVENTS.csv', low_memory=False)\n",
    "patients_df = pd.read_csv('Data/PATIENTS.csv', low_memory=False)\n",
    "admissions_df = pd.read_csv('Data/ADMISSIONS.csv',  low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>22532</td>\n",
       "      <td>167853.0</td>\n",
       "      <td>2151-08-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>13702</td>\n",
       "      <td>107527.0</td>\n",
       "      <td>2118-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>13702</td>\n",
       "      <td>167118.0</td>\n",
       "      <td>2119-05-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>13702</td>\n",
       "      <td>196489.0</td>\n",
       "      <td>2124-08-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>26880</td>\n",
       "      <td>135453.0</td>\n",
       "      <td>2162-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
       "0     174       22532  167853.0  2151-08-04       NaN       NaN   \n",
       "1     175       13702  107527.0  2118-06-14       NaN       NaN   \n",
       "2     176       13702  167118.0  2119-05-25       NaN       NaN   \n",
       "3     177       13702  196489.0  2124-08-18       NaN       NaN   \n",
       "4     178       26880  135453.0  2162-03-25       NaN       NaN   \n",
       "\n",
       "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
       "0  Discharge summary      Report   NaN      NaN   \n",
       "1  Discharge summary      Report   NaN      NaN   \n",
       "2  Discharge summary      Report   NaN      NaN   \n",
       "3  Discharge summary      Report   NaN      NaN   \n",
       "4  Discharge summary      Report   NaN      NaN   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
       "2  Admission Date:  [**2119-5-4**]              D...  \n",
       "3  Admission Date:  [**2124-7-21**]              ...  \n",
       "4  Admission Date:  [**2162-3-3**]              D...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just a look of the the noteevent \n",
    "note_event_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the doc2text\n",
    "\"\"\"\n",
    "ROW ID as the key\n",
    "Notes as the item\n",
    "Target: Reduce the read the note.csv several times. We will\n",
    "use the row id as the index to connect the other info\n",
    "\"\"\"\n",
    "\n",
    "# Convert the Noteevents to the pickle files\n",
    "note_required_text = note_event_df.set_index('ROW_ID')['TEXT'].to_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">We already the doc2text file and we have <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2083180</span> clinical notes.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "We already the doc2text file and we have \u001b[1;36m2083180\u001b[0m clinical notes.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the dictionary into the pickle file doc2text\n",
    "with open('doc2text.pickle', 'wb') as f:\n",
    "    pickle.dump(note_required_text, f)\n",
    "\n",
    "size_note = len(note_required_text)\n",
    "# Check the size of the noteevents and the pickle file already generated\n",
    "print(f\"We already the doc2text file and we have {size_note} clinical notes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Opened doc2text pickle file\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Opened doc2text pickle file\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If we have a doc2text right now, we need to load it\n",
    "with open('doc2text.pickle', 'rb') as f:\n",
    "    doc2text = pickle.load(f)\n",
    "print(\"Opened doc2text pickle file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">174</span> =&gt;\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'SUBJECT_ID'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22532</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'CHARTDATE'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2151-08-04'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m174\u001b[0m =>\n",
       "\u001b[1m{\u001b[0m\u001b[32m'SUBJECT_ID'\u001b[0m: \u001b[1;36m22532\u001b[0m, \u001b[32m'CHARTDATE'\u001b[0m: \u001b[32m'2151-08-04'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">175</span> =&gt;\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'SUBJECT_ID'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13702</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'CHARTDATE'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2118-06-14'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m175\u001b[0m =>\n",
       "\u001b[1m{\u001b[0m\u001b[32m'SUBJECT_ID'\u001b[0m: \u001b[1;36m13702\u001b[0m, \u001b[32m'CHARTDATE'\u001b[0m: \u001b[32m'2118-06-14'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">176</span> =&gt;\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'SUBJECT_ID'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13702</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'CHARTDATE'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2119-05-25'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m176\u001b[0m =>\n",
       "\u001b[1m{\u001b[0m\u001b[32m'SUBJECT_ID'\u001b[0m: \u001b[1;36m13702\u001b[0m, \u001b[32m'CHARTDATE'\u001b[0m: \u001b[32m'2119-05-25'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "construct the doc2info dictionary, the key should be the row id and the \n",
    "chartdate and subject id should be value\n",
    "\"\"\"\n",
    "doc2info = {}\n",
    "info_df = note_event_df[['ROW_ID', 'SUBJECT_ID', 'CHARTDATE']]\n",
    "doc2info = info_df.set_index('ROW_ID').to_dict(orient='index')\n",
    "\n",
    "# Check for the first 3 dict\n",
    "for doc_id, info in list(doc2info.items())[:3]:\n",
    "    print(doc_id, \"=>\", info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning method \n",
    "def data_clean(text):\n",
    "    # Remove this format\n",
    "    # Remove the token like this \"[**Name**]\"\n",
    "    clean_step1 = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', ' ', text)\n",
    "    cleaned = re.sub(r'\\s+', ' ', clean_step1)\n",
    "    final_cleaned = cleaned.strip()\n",
    "    return final_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the clean function\n",
    "for id, text in doc2text.items():\n",
    "    doc2text[id] = data_clean(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">174</span> =&gt; Admission Date: Discharge Date: Service: ADDENDUM: RADIOLOGIC STUDIES: Radiologic studies also included a \n",
       "chest CT, which confirmed cavitary lesions in the left lung apex consistent with infectious process/tuberculosis. \n",
       "This also moderate-sized left pleural effusion. HEAD CT: Head CT showed no intracranial hemorrhage or mass effect, \n",
       "but old infarction consistent with past medical history. ABDOMINAL CT: Abdominal CT showed lesions of T10 and \n",
       "sacrum most likely secondary to osteoporosis. These can be followed by repeat imaging as an outpatient. , M.D. \n",
       "Dictated By: MEDQUIST36 D: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:11</span> T: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:21</span> JOB#:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m174\u001b[0m => Admission Date: Discharge Date: Service: ADDENDUM: RADIOLOGIC STUDIES: Radiologic studies also included a \n",
       "chest CT, which confirmed cavitary lesions in the left lung apex consistent with infectious process/tuberculosis. \n",
       "This also moderate-sized left pleural effusion. HEAD CT: Head CT showed no intracranial hemorrhage or mass effect, \n",
       "but old infarction consistent with past medical history. ABDOMINAL CT: Abdominal CT showed lesions of T10 and \n",
       "sacrum most likely secondary to osteoporosis. These can be followed by repeat imaging as an outpatient. , M.D. \n",
       "Dictated By: MEDQUIST36 D: \u001b[1;92m12:11\u001b[0m T: \u001b[1;92m12:21\u001b[0m JOB#:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Small check for the cleaned data\n",
    "for doc_id, text in list(doc2text.items())[:1]:\n",
    "    print(doc_id, \"=>\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_medcat_entity(text):\n",
    "    entities_info = []\n",
    "    doc = cat.get_entities(text)\n",
    "    for row_id, entity in doc['entities'].items():\n",
    "        if not isinstance(entity, dict):\n",
    "            continue\n",
    "        try:\n",
    "            cui = entity.get('cui')\n",
    "            name = entity.get('pretty_name')\n",
    "            sem_type = entity.get('types',[])\n",
    "            print(sem_type)\n",
    "            start = entity.get('start')\n",
    "            end = entity.get('end')\n",
    "            if 'meta_anns' in entity:\n",
    "                status_info = entity['meta_anns'].get('Status')  # or whatever your meta model's name is\n",
    "            if status_info:\n",
    "                status = status_info.get('value')  # e.g. \"Affirmed\" vs \"Negated\"\n",
    "            # Find the current content (+50 tokens)\n",
    "            sent_start = text.rfind('.', 0, start) \n",
    "            sent_end = text.find('.', end)   \n",
    "            if sent_start == -1:\n",
    "                sent_start = max(0, start - 50) # Paper mentioned\n",
    "            else:\n",
    "                sent_start += 1 \n",
    "            if sent_end == -1:\n",
    "                sent_end = min(len(text), end + 50)\n",
    "            context_sentence = text[sent_start:sent_end].strip()\n",
    "\n",
    "            entities_info.append({\n",
    "                'cui': cui,\n",
    "                'name': name,\n",
    "                'type': sem_type,\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'context': context_sentence\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entity: {entity}\")\n",
    "            continue\n",
    "    return entities_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Type \n",
    "target_types = {'disorders','symptoms', 'findings', 'medications'}\n",
    "\n",
    "# We should replace the medicak concept with the cui \n",
    "def replace_text_cui(text, entities):\n",
    "    # Sort thhe enitities through the start index which may help us to avoid modify the position of \n",
    "    entities = sorted(entities, key = lambda e: e['start'])\n",
    "    result_parts = []\n",
    "    last_index = 0\n",
    "    for ent in entities:\n",
    "        # Skip the type we do not expect\n",
    "        if ent['type'] not in target_types:\n",
    "            continue\n",
    "        # Append the text from the last index to next enitity\n",
    "        result_parts.append(text[last_index : ent['start']])\n",
    "        # Append the CUI code in place of the concept mention\n",
    "        result_parts.append(ent['cui'])\n",
    "        # Update the last index to the end of the replaced entity\n",
    "        last_idx = ent['end']\n",
    "    # Append any remaining text after the last entity\n",
    "    result_parts.append(text[last_idx:])\n",
    "    # Join all parts into the final text\n",
    "    return \"\".join(result_parts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
